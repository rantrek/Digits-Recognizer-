{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Digit Recognition using Python and Machine Learning\n",
    "#Dataset downloaded from kaggle website, https://www.kaggle.com/c/digit-recognizer/data\n",
    "#Received an accuracy score of 0.97885 for my submission for the kaggle competition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training and test data\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n",
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "print (train_data.head())\n",
    "print (train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate x and y columns\n",
    "\n",
    "train = train_data.iloc[:,1:].values # all pixel values\n",
    "labels = train_data.iloc[:,0].values # only labels i.e targets digits\n",
    "test = test_data.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading images into numpy array and reshaping it\n",
    "\n",
    "train =train.reshape(train.shape[0], 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing a single image using matplotlib\n",
    "\n",
    "plt.imshow(train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.title(labels[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a dimension to the data\n",
    "x_train = train.reshape(train.shape[0], 28, 28,1)\n",
    "x_test = test.reshape(test.shape[0], 28, 28,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training and testing case\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#x_train, x_test, y_train, y_test = train_test_split(train, labels,\n",
    "                                                    #test_size=0.2,\n",
    "                                                    #stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                    rotation_range=10,\n",
    "                                    zoom_range=0.15, \n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1)\n",
    "test_generator = ImageDataGenerator(rescale = 1./255)\n",
    "train_generator.fit(x_train)\n",
    "test_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#Convert data type \n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000,)\n",
      "[1 0 1 4 0 0 7 3 5 3]\n"
     ]
    }
   ],
   "source": [
    "#Pre-processing the labels column\n",
    "\n",
    "print(labels.shape)\n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 10)\n"
     ]
    }
   ],
   "source": [
    "#Convert 1-dimensional class arrays to 10-dimensional class matrices for labels\n",
    "Y_train = np_utils.to_categorical(labels, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying CNN deep learning model to the data\n",
    "\n",
    "#Initializing the CNN\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolution\n",
    "#Adding 1st layer\n",
    "model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "\n",
    "#Adding 2nd layer\n",
    "model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "#Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "#Full Connection\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the CNN\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "42000/42000 [==============================] - 201s 5ms/step - loss: 0.6282 - accuracy: 0.8693\n",
      "Epoch 2/2\n",
      "42000/42000 [==============================] - 217s 5ms/step - loss: 0.1691 - accuracy: 0.9506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xc40affa6a0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the CNN to the images\n",
    "\n",
    "model.fit(x_train, Y_train, \n",
    "          batch_size=32, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score = model.evaluate(x_test, Y_test, verbose=0)\n",
    "#print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 9 ... 3 9 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28000"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using CNN model to make predictions for the test set\n",
    "\n",
    "results = model.predict_classes(x_test, verbose=0)\n",
    "print(results)\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Storing the predictions in the csv file\n",
    "\n",
    "df = pd.DataFrame({\"ImageId\": list(range(1,len(results)+1)),\n",
    "                         \"Label\": results})\n",
    "df.to_csv('submission.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
